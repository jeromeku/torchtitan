# ---- All project specifications ---- #
[project]
name = "torchtitan"
description = "A PyTorch native platform for training generative AI models"
readme = "README.md"
requires-python = ">=3.10"
license = {file = "LICENSE"}
authors = [
    { name = "PyTorch Team", email = "packages@pytorch.org" },
]
keywords = ["pytorch", "training", "llm"]
dependencies = [
    # Stateful Dataloader
    "torchdata>=0.8.0",

    # Hugging Face integrations
    "datasets>=2.21.0",

    # Tokenization
    "tokenizers",

    # Miscellaneous
    "tomli>=1.1.0",
    "fsspec",
    "tyro",
    "tensorboard",
]
dynamic = ["version"]

[project.urls]
GitHub = "https://github.com/pytorch/torchtitan"
Documentation = "https://github.com/pytorch/torchtitan/tree/main/docs"
Issues = "https://github.com/pytorch/torchtitan/issues"

[project.optional-dependencies]
dev = [
    "pre-commit",
    "pytest",
    "pytest-cov",
    "wandb"
]
custom = [
    "nvidia-cutlass-dsl",
    # Install from local submodule instead of PyPI:
    # If flashinfer’s pyproject name is "flashinfer-python", keep this as-is.
    # If it’s "flashinfer", change the left side to match (e.g., "flashinfer @ ...").
    # "flashinfer-python @ ./thirdparty/flashinfer"
]

[tool.setuptools.dynamic]
version = {file = "assets/version.txt"}

# If you use uv (recommended), this forces local path resolution even if a wheel exists on PyPI.
[tool.uv.sources]
flashinfer-python = { path = "thirdparty/flashinfer" }

# ---- Explicit project build information ---- #
[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[tool.setuptools.packages.find]
where = [""]
include = ["torchtitan*"]

[tool.pytest.ini_options]
addopts = ["--showlocals"]  # show local variables in tracebacks
